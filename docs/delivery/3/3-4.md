# [3-4] Implement core import script

[Back to task list](./tasks.md)

## Description

Create the main import script that uses ogr2ogr to load GeoJSON data into PostgreSQL. This script will read the field mapping configuration, execute the import with proper parameters, and handle the complete import workflow including transaction management.

**Note**: Using GeoJSON format (our standard) with ogr2ogr for maximum compatibility and flexibility.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2025-10-20 12:00:00 | Created | N/A | Proposed | Task file created | AI_Agent |
| 2025-10-20 16:00:00 | Status Change | Proposed | Agreed | Task approved by User | User |
| 2025-10-20 16:00:01 | Status Change | Agreed | InProgress | Starting implementation of import script using ogr2ogr | AI_Agent |
| 2025-10-20 20:56:00 | Status Change | InProgress | Review | Import script completed and tested with 324,597 records | AI_Agent |
| 2025-10-20 21:00:00 | Status Change | Review | Done | Task approved and completed by User | User |

## Requirements

1. Accept GeoJSON file path and mapping configuration as arguments
2. Read field mapping configuration from JSON
3. Construct ogr2ogr command with appropriate parameters:
   - CRS transformation (-t_srs TARGET_CRS)
   - PostgreSQL connection string
   - Target table name (tax_parcels_staging)
   - Geometry column name
4. Execute import within a database transaction
5. Handle field name mapping with SQL INSERT from staging to final table
6. Support both full import and append modes
7. Provide database connection configuration (host, port, database, user)
8. Handle errors and provide clear error messages
9. Support dry-run mode to preview operations without executing

## Implementation Plan

1. Create script: `scripts/import-parcels.sh`
2. Implement command-line argument parsing:
   - `--file <path>` (GeoJSON file path)
   - `--mapping <config.json>`
   - `--db-host <host>`
   - `--db-name <database>`
   - `--db-user <user>`
   - `--mode <append|replace>`
   - `--dry-run`
3. Read and parse JSON mapping configuration
4. Extract source/target CRS from mapping config
5. Construct ogr2ogr command for staging import:
   ```bash
   ogr2ogr -f PostgreSQL \
     PG:"host=${HOST} dbname=${DB} user=${USER}" \
     ${GEOJSON_FILE} \
     -nln tax_parcels_staging \
     -t_srs EPSG:4326
   ```
6. Generate SQL to map fields from staging to final table:
   ```sql
   INSERT INTO tax_parcels (object_id, pin, owner_name, situs, geom)
   SELECT "OBJECTID", "PIN", "ownerName", "situs", geom
   FROM tax_parcels_staging;
   ```
7. Execute within transaction wrapper
8. Add error checking at each step
9. Provide clear status messages during import
10. Document usage and examples

## Test Plan

**Objective**: Verify the import script successfully loads GeoJSON data into PostgreSQL

**Test Scope**: Bash script execution and database integration

**Key Test Scenarios**:
1. Script accepts all required arguments
2. Script reads and parses JSON configuration
3. Script constructs valid ogr2ogr command
4. Script successfully imports Montgomery County GeoJSON (325k records)
5. CRS transformation is applied correctly (if needed)
6. Existing spatial index from migrations is used
7. Geometries are imported correctly
8. Script handles missing required arguments gracefully
9. Dry-run mode shows commands without executing

**Success Criteria**: 
- Script successfully imports test data
- All geometries are transformed to EPSG:4326
- Spatial index is created and functional
- Script provides clear progress and error messages
- Transaction rollback works on error

## Verification

- [x] Script created at `scripts/import-parcels.sh`
- [x] Script is executable (chmod +x)
- [x] Script accepts all required arguments
- [x] Script reads JSON mapping configuration
- [x] Script constructs correct ogr2ogr command
- [x] Script generates field mapping SQL
- [x] Script executes within transaction
- [x] CRS is verified (EPSG:4326 for Montgomery County)
- [x] Script handles field name mapping via SQL
- [x] Script includes error handling
- [x] Script includes usage documentation
- [x] Script tested with Montgomery County data (325,071 records)
- [x] Import completes successfully (324,597 records imported)

## Files Modified

- `scripts/import-parcels.sh` (new)
- `api/migrations/000004_change_geom_to_multipolygon.up.sql` (new)
- `api/migrations/000004_change_geom_to_multipolygon.down.sql` (new)
- `api/migrations/000005_increase_lot_column_length.up.sql` (new)
- `api/migrations/000005_increase_lot_column_length.down.sql` (new)

## Implementation Notes

**Import Results:**
- Successfully imported 324,597 parcel records from Montgomery County, TX
- Filtered out 12 records with NULL geometries
- Filtered out 462 records with NULL PINs
- All geometries converted to MultiPolygon format using ST_Multi()
- Spatial index (idx_parcels_geom) verified functional with 0.138ms query time

**Schema Updates Required:**
1. Changed `geom` column from `GEOMETRY(Polygon, 4326)` to `GEOMETRY(MultiPolygon, 4326)` to support both Polygon and MultiPolygon geometries
2. Increased `lot` column from VARCHAR(50) to VARCHAR(100) to accommodate real data (max length: 78 chars)

**Technical Decisions:**
- Used ogr2ogr for GeoJSON import (native support, no conversion needed)
- Implemented two-stage import: GeoJSON → staging table → final table with field mapping
- Field names converted to lowercase by ogr2ogr automatically
- Transaction-based import with rollback on error
- Dry-run mode for testing without database changes


