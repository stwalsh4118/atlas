# [5-8] Query performance optimization and monitoring

[Back to task list](./tasks.md)

## Description

Verify and optimize the performance of spatial queries to meet the < 100ms target. Add query timing instrumentation, verify spatial index usage with EXPLAIN ANALYZE, and add performance monitoring. This task ensures the API meets the performance acceptance criteria defined in the PRD.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2025-10-21 12:00:00 | Created | N/A | Proposed | Task file created | AI_Agent |

## Requirements

1. Add query timing instrumentation to all repository methods
2. Log query execution time with structured logging
3. Run EXPLAIN ANALYZE on all spatial queries
4. Verify GiST spatial index is being used
5. Add performance tests with realistic data volumes (50k+ parcels)
6. Ensure point-in-polygon queries complete in < 100ms
7. Optimize queries if performance targets not met
8. Document query performance characteristics

## Implementation Plan

1. **Add Query Timing to Repository**:
   - Wrap all SQL queries with timing instrumentation
   - Log execution time using structured logging
   ```go
   func (r *parcelRepository) FindByPoint(ctx context.Context, lat, lng float64) (*models.TaxParcel, error) {
       start := time.Now()
       defer func() {
           duration := time.Since(start)
           r.log.Info("Query executed", map[string]interface{}{
               "method": "FindByPoint",
               "duration_ms": duration.Milliseconds(),
               "lat": lat,
               "lng": lng,
           })
       }()
       
       // ... existing query logic
   }
   ```

2. **Create EXPLAIN ANALYZE Script**:
   - Create `scripts/analyze-spatial-queries.sh`
   - Run EXPLAIN ANALYZE on all spatial queries
   - Verify index usage:
     - Should see "Index Scan using idx_parcels_geom"
     - Should NOT see "Seq Scan"
   - Document output in task file

3. **Performance Testing**:
   - Create `api/internal/repository/parcel_repository_bench_test.go`
   - Benchmark tests for all three query methods
   - Test with dataset of 50k+ parcels
   - Measure P50, P95, P99 latencies
   ```go
   func BenchmarkFindByPoint(b *testing.B) {
       // Setup test database with 50k parcels
       // Run FindByPoint b.N times
       // Report timing
   }
   ```

4. **Add Performance Monitoring**:
   - Log slow queries (> 200ms) at WARN level
   - Include query parameters for debugging
   - Consider adding query timeout (5 seconds)

5. **Optimization if Needed**:
   - If queries > 100ms, investigate:
     - Is spatial index present? (`\di` in psql)
     - Is index being used? (EXPLAIN ANALYZE)
     - Are there unnecessary JOINs?
     - Is LIMIT being applied correctly?
   - Common fixes:
     - Ensure VACUUM ANALYZE has run
     - Adjust work_mem if needed
     - Use ST_Intersects instead of ST_Contains for bbox queries
     - Simplify geometry if too complex

## Test Plan

**Objective**: Verify all spatial queries meet performance targets with production-like data

**Test Scope**: Performance testing and query plan analysis

**Environment & Setup**:
- PostgreSQL database with 50k+ tax parcels
- Real Montgomery County data if available
- Run VACUUM ANALYZE before testing
- Clear buffer cache between tests for consistency

**Key Test Scenarios**:
1. **Point-in-polygon performance**: 100 random queries, measure P95 < 100ms
2. **Nearby query performance**: 100 random queries with 1000m radius, measure P95 < 200ms
3. **Get by ID performance**: 100 random lookups, measure P95 < 10ms
4. **Cold cache**: First query after DB restart (acceptable to be slower)
5. **Concurrent queries**: 10 concurrent requests, no performance degradation
6. **Query plan verification**: EXPLAIN ANALYZE shows index usage for all queries

**Success Criteria**:
- Point-in-polygon queries: P95 < 100ms, P99 < 150ms
- Nearby queries: P95 < 200ms, P99 < 300ms
- Get by ID: P95 < 10ms
- All spatial queries use GiST index (confirmed via EXPLAIN ANALYZE)
- No sequential scans on tax_parcels table for spatial queries
- Query timing logged for all queries
- Slow queries (> 200ms) logged at WARN level

## Verification

- [ ] Query timing added to all repository methods
- [ ] Execution time logged with structured logging
- [ ] EXPLAIN ANALYZE script created and run
- [ ] Spatial index usage verified for all queries
- [ ] Benchmark tests created and passing
- [ ] Performance targets met (P95 < 100ms for at-point)
- [ ] Slow query logging implemented (> 200ms)
- [ ] Performance test results documented
- [ ] Query plans documented in this task file
- [ ] Code compiles and lints cleanly

## Implementation Notes

### EXPLAIN ANALYZE Results

(To be filled in during implementation)

**FindByPoint Query**:
```
-- EXPLAIN ANALYZE output here
```

**FindNearby Query**:
```
-- EXPLAIN ANALYZE output here
```

**FindByID Query**:
```
-- EXPLAIN ANALYZE output here
```

### Performance Test Results

(To be filled in during implementation)

| Query Type | P50 | P95 | P99 | Target Met? |
|------------|-----|-----|-----|-------------|
| At Point   | -   | -   | -   | -           |
| Nearby     | -   | -   | -   | -           |
| By ID      | -   | -   | -   | -           |

## Files Modified

- `api/internal/repository/parcel_repository.go` (updated - add timing)
- `api/internal/repository/parcel_repository_bench_test.go` (created)
- `scripts/analyze-spatial-queries.sh` (created)
- `docs/delivery/5/5-8.md` (updated with results)

